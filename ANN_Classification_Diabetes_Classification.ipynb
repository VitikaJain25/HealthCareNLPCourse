{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN Classification - Diabetes Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHCrviyWp/Ar3lMi8b2YMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitikaJain25/HealthCareNLPCourse/blob/main/ANN_Classification_Diabetes_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kMVX9LNdFivz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes = pd.read_csv(\"https://raw.githubusercontent.com/VitikaJain25/MLDataSets/main/diabetes.csv\")\n",
        "diabetes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "QXKI6W0vGFX2",
        "outputId": "a2d5cc1c-4edc-40f1-abfc-59ed4cda78b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d0c7e66-daf7-45c3-b615-5aea573b4985\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d0c7e66-daf7-45c3-b615-5aea573b4985')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d0c7e66-daf7-45c3-b615-5aea573b4985 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d0c7e66-daf7-45c3-b615-5aea573b4985');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Manipulation"
      ],
      "metadata": {
        "id": "8-mhjU0qHY__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All data is numerical\n",
        "diabetes.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HmjViQpHKdW",
        "outputId": "fc3c602e-4715-4f40-c7db-1074f68e9817"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes.describe()\n",
        "# Problem is Glucose, BP, Insulin cannot be 0.\n",
        "# Outcome = 0 mean person is not diabetic, 1 means person is diabetic."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "PsnpR99eHfJ0",
        "outputId": "df36d08f-7624-45c5-8d3e-ed183493d289"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
              "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
              "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
              "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
              "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
              "count  768.000000                768.000000  768.000000  768.000000  \n",
              "mean    31.992578                  0.471876   33.240885    0.348958  \n",
              "std      7.884160                  0.331329   11.760232    0.476951  \n",
              "min      0.000000                  0.078000   21.000000    0.000000  \n",
              "25%     27.300000                  0.243750   24.000000    0.000000  \n",
              "50%     32.000000                  0.372500   29.000000    0.000000  \n",
              "75%     36.600000                  0.626250   41.000000    1.000000  \n",
              "max     67.100000                  2.420000   81.000000    1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c14dbcf4-6a67-43e7-a356-b5b2185b0719\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c14dbcf4-6a67-43e7-a356-b5b2185b0719')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c14dbcf4-6a67-43e7-a356-b5b2185b0719 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c14dbcf4-6a67-43e7-a356-b5b2185b0719');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Pregnancies column as it can be zero. Other columns cannot be zero.\n",
        "data_raw = diabetes.drop(['Pregnancies', 'Outcome'], axis = 1)"
      ],
      "metadata": {
        "id": "rUUa477wIEbi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other columns cannot be zero, so replacing 0 by np.nan to find missing values.\n",
        "data_raw.replace(0, np.nan, inplace = True)"
      ],
      "metadata": {
        "id": "gl-3uBufIaIL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the missing values.\n",
        "data_raw.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EekDlJQlIkJR",
        "outputId": "ceaba32b-17f1-498e-c1cd-b34b7cc58993"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Insulin                     374\n",
              "SkinThickness               227\n",
              "BloodPressure                35\n",
              "BMI                          11\n",
              "Glucose                       5\n",
              "DiabetesPedigreeFunction      0\n",
              "Age                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handeling Missing Values"
      ],
      "metadata": {
        "id": "8hUyR8ZvJTbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If data is continous, replace by Mean.\n",
        "# If data is discrete, replace by Median.\n",
        "# If data is non-numerical, replace by Mode.\n",
        "\n",
        "# Using unique() to find out the type of values (continous, discrete)\n",
        "data_raw['Insulin'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmM1JDntJRfQ",
        "outputId": "45ed473c-b6b9-4708-b8b2-9409891289b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ nan,  94., 168.,  88., 543., 846., 175., 230.,  83.,  96., 235.,\n",
              "       146., 115., 140., 110., 245.,  54., 192., 207.,  70., 240.,  82.,\n",
              "        36.,  23., 300., 342., 304., 142., 128.,  38., 100.,  90., 270.,\n",
              "        71., 125., 176.,  48.,  64., 228.,  76., 220.,  40., 152.,  18.,\n",
              "       135., 495.,  37.,  51.,  99., 145., 225.,  49.,  50.,  92., 325.,\n",
              "        63., 284., 119., 204., 155., 485.,  53., 114., 105., 285., 156.,\n",
              "        78., 130.,  55.,  58., 160., 210., 318.,  44., 190., 280.,  87.,\n",
              "       271., 129., 120., 478.,  56.,  32., 744., 370.,  45., 194., 680.,\n",
              "       402., 258., 375., 150.,  67.,  57., 116., 278., 122., 545.,  75.,\n",
              "        74., 182., 360., 215., 184.,  42., 132., 148., 180., 205.,  85.,\n",
              "       231.,  29.,  68.,  52., 255., 171.,  73., 108.,  43., 167., 249.,\n",
              "       293.,  66., 465.,  89., 158.,  84.,  72.,  59.,  81., 196., 415.,\n",
              "       275., 165., 579., 310.,  61., 474., 170., 277.,  60.,  14.,  95.,\n",
              "       237., 191., 328., 250., 480., 265., 193.,  79.,  86., 326., 188.,\n",
              "       106.,  65., 166., 274.,  77., 126., 330., 600., 185.,  25.,  41.,\n",
              "       272., 321., 144.,  15., 183.,  91.,  46., 440., 159., 540., 200.,\n",
              "       335., 387.,  22., 291., 392., 178., 127., 510.,  16., 112.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(data_raw['Insulin'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7zXZWJBJ15g",
        "outputId": "2316c0c5-1b3c-461f-ec48-a45c0ab9a63c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace Missing values with Mean for \"Insulin\" column.\n",
        "# Replacing nan value with Mean value for the column \"Insulin\".\n",
        "data_raw['Insulin'].replace(np.nan, np.round(data_raw['Insulin'].mean()), inplace = True)"
      ],
      "metadata": {
        "id": "3lyzZRQjJ8AR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verfying the values for Insulin column.\n",
        "data_raw.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# Insuline column now has 0 missing / nan values."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gXhfUl8KTyn",
        "outputId": "fea267c2-c42a-46f8-c2bb-a91e91c9b7c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SkinThickness               227\n",
              "BloodPressure                35\n",
              "BMI                          11\n",
              "Glucose                       5\n",
              "Insulin                       0\n",
              "DiabetesPedigreeFunction      0\n",
              "Age                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  If we want to remove missing or nan values from multiple columns, then instead of doing it one by one we can use Imputer\n",
        "*   The data type changes from Dataframe to Array.\n",
        "*   Simple Imputer targets only nan values that is why we converted 0 values to nan values before replacing with mean value.\n",
        "*   If we do not want to use an imputer, then we can directly convert the 0 values to mean value (no need to convert to nan)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ki_vz9YRKhpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Data type changes from Dataframe to Array.\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Strategy = 'median', 'mean', 'mode'\n",
        "impute = SimpleImputer(strategy = 'median')\n",
        "data_array = impute.fit_transform(data_raw)"
      ],
      "metadata": {
        "id": "tfdRJPGNKhFt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWk7oK-cLDYa",
        "outputId": "7c4c767b-b862-4944-e2f4-a2a96a86baf8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[148.   ,  72.   ,  35.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [ 85.   ,  66.   ,  29.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [183.   ,  64.   ,  29.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [121.   ,  72.   ,  23.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [126.   ,  60.   ,  29.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [ 93.   ,  70.   ,  31.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So we have to convert the array back to a Dataframe.\n",
        "diabetes_df = pd.DataFrame(data_array, columns = data_raw.columns)\n",
        "diabetes_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "T9EYpfB2LPq3",
        "outputId": "41bf72e7-943c-484b-80e6-03a162140c41"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0      148.0           72.0           35.0    156.0  33.6   \n",
              "1       85.0           66.0           29.0    156.0  26.6   \n",
              "2      183.0           64.0           29.0    156.0  23.3   \n",
              "3       89.0           66.0           23.0     94.0  28.1   \n",
              "4      137.0           40.0           35.0    168.0  43.1   \n",
              "..       ...            ...            ...      ...   ...   \n",
              "763    101.0           76.0           48.0    180.0  32.9   \n",
              "764    122.0           70.0           27.0    156.0  36.8   \n",
              "765    121.0           72.0           23.0    112.0  26.2   \n",
              "766    126.0           60.0           29.0    156.0  30.1   \n",
              "767     93.0           70.0           31.0    156.0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction   Age  \n",
              "0                       0.627  50.0  \n",
              "1                       0.351  31.0  \n",
              "2                       0.672  32.0  \n",
              "3                       0.167  21.0  \n",
              "4                       2.288  33.0  \n",
              "..                        ...   ...  \n",
              "763                     0.171  63.0  \n",
              "764                     0.340  27.0  \n",
              "765                     0.245  30.0  \n",
              "766                     0.349  47.0  \n",
              "767                     0.315  23.0  \n",
              "\n",
              "[768 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8f8e2a1-9f28-44de-80e7-877f04e0664b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>183.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>89.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>101.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>122.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>121.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>126.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>93.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8f8e2a1-9f28-44de-80e7-877f04e0664b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8f8e2a1-9f28-44de-80e7-877f04e0664b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8f8e2a1-9f28-44de-80e7-877f04e0664b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df['Pregnancies'] = diabetes.Pregnancies\n",
        "diabetes_df['Outcome'] = diabetes.Outcome"
      ],
      "metadata": {
        "id": "hT7ZbHJ4PXAc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "9FrKUgx8PpRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x = \"Outcome\", kind = \"count\", data = diabetes_df, palette = 'magma')\n",
        "\n",
        "# Output class is not balanced."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "L-B8zfPzPr1u",
        "outputId": "12a8e9be-bb29-4b50-ef37-3335a3239549"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fca1f90cbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imbalanced class\n",
        "diabetes_df['Outcome'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJJtPS_HQX-Q",
        "outputId": "6ca89fbe-803d-4346-9e69-73ab61a2f5cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    500\n",
              "1    268\n",
              "Name: Outcome, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Oversampling \n",
        "# Resample using \"bootstrapping\" method to generate samples by upsampling for each class\n",
        "from sklearn.utils import resample\n",
        "df_0 = diabetes_df[diabetes_df['Outcome'] == 0]\n",
        "df_1 = diabetes_df[diabetes_df['Outcome'] == 1]"
      ],
      "metadata": {
        "id": "FHJvaxLCRlom"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Resampling\n",
        "# Upsampling\n",
        "df_1_upsample = resample(df_1, n_samples = 500, replace = True, random_state = 123)"
      ],
      "metadata": {
        "id": "eDkEqpu4Rnvz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df1 = pd.concat([df_0, df_1_upsample])"
      ],
      "metadata": {
        "id": "iaUm-RjqRrkP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x = \"Outcome\", kind = \"count\", data = diabetes_df1, palette = 'magma')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "Qn0d1dhsRtbS",
        "outputId": "bca4d838-c1f9-4f15-aa6e-abdebed14873"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fca1caf09d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train and Test"
      ],
      "metadata": {
        "id": "_nydhPY5StV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = diabetes_df1.drop(['Outcome'], axis = 1)\n",
        "Y = diabetes_df1['Outcome']"
      ],
      "metadata": {
        "id": "oPxqquhNSvmN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)"
      ],
      "metadata": {
        "id": "bFmUGmfOTR10"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANN Classification"
      ],
      "metadata": {
        "id": "feY8O1dFT-M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout is used to handle issue like overfitting.\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Optimizers\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "doZ4LoYqTjKe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  # Sequential Neural Network - FeedForward Neural Network\n",
        "  # Randomly have to choose the units value.\n",
        "  # We can give different combination of values for the units value. We can write a function and start a loop. At end we will know whcih \n",
        "  #combination of values are giving the best accuracy.\n",
        "\n",
        "  model = Sequential()\n",
        "  # Units = Num of Neurons (2 * pow(n)), input shape = Num of Features.\n",
        "  model.add(Dense(units = 64, activation = 'relu', input_shape = [len(X.keys())]))\n",
        "  \n",
        "  # Hidden layer - 1\n",
        "  model.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "  # Hidden layer - 2\n",
        "  model.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "  # Output Layer - For Classification\n",
        "  model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "  # Optimizers\n",
        "  optimizers = Adam(learning_rate=0.001)\n",
        "\n",
        "  # Model Compiler\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = optimizers, metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "  # Without Dropout"
      ],
      "metadata": {
        "id": "355QO5f2U0Zn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "HsWMMUMzVjyE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdYi4plAVmAw",
        "outputId": "1c7d6a86-b9fe-4dd0-b55d-376bb30f2360"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 64)                576       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,537\n",
            "Trainable params: 25,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Epochs = Number of Iterations\n",
        "# epochs are choosen randomly. If accuracy is low, try increasing the epochs.\n",
        "# Batch size - no of samples per iteration.\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 500, batch_size = 25, validation_split = 0.15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8pmp8krWASg",
        "outputId": "4de3d7a7-c4b0-4dbc-ccba-79ceec9a5df2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "28/28 [==============================] - 1s 11ms/step - loss: 1.6794 - accuracy: 0.5779 - val_loss: 0.9822 - val_accuracy: 0.6083\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0137 - accuracy: 0.5794 - val_loss: 0.7596 - val_accuracy: 0.6500\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8821 - accuracy: 0.6103 - val_loss: 0.5511 - val_accuracy: 0.6833\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.6338 - val_loss: 0.5470 - val_accuracy: 0.7000\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7340 - accuracy: 0.6265 - val_loss: 0.5893 - val_accuracy: 0.7500\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.6721 - val_loss: 0.5657 - val_accuracy: 0.6750\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6897 - val_loss: 0.8115 - val_accuracy: 0.6333\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.9946 - accuracy: 0.5912 - val_loss: 1.2304 - val_accuracy: 0.5667\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.6574 - val_loss: 0.6216 - val_accuracy: 0.7417\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6926 - val_loss: 0.5335 - val_accuracy: 0.7333\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6574 - val_loss: 0.6220 - val_accuracy: 0.6750\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6735 - val_loss: 0.5528 - val_accuracy: 0.7083\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7118 - val_loss: 0.9012 - val_accuracy: 0.5000\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6603 - val_loss: 0.5874 - val_accuracy: 0.7667\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7059 - val_loss: 0.5754 - val_accuracy: 0.6917\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7147 - val_loss: 0.6437 - val_accuracy: 0.7000\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.6765 - val_loss: 0.5297 - val_accuracy: 0.7417\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.6956 - val_loss: 0.5721 - val_accuracy: 0.7333\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7471 - val_loss: 0.6162 - val_accuracy: 0.6667\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6750 - val_loss: 0.6591 - val_accuracy: 0.6583\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.6971 - val_loss: 0.7944 - val_accuracy: 0.6333\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7176 - val_loss: 0.5489 - val_accuracy: 0.7083\n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7382 - val_loss: 0.6312 - val_accuracy: 0.7250\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.7103 - val_loss: 0.5170 - val_accuracy: 0.7667\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7235 - val_loss: 0.7145 - val_accuracy: 0.6917\n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7118 - val_loss: 0.5248 - val_accuracy: 0.7417\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7426 - val_loss: 0.6285 - val_accuracy: 0.6750\n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7485 - val_loss: 0.8534 - val_accuracy: 0.5833\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7426 - val_loss: 0.5913 - val_accuracy: 0.7250\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.7059 - val_loss: 0.5656 - val_accuracy: 0.6917\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6941 - val_loss: 0.6872 - val_accuracy: 0.6500\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.7147 - val_loss: 0.7396 - val_accuracy: 0.6667\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7147 - val_loss: 0.5641 - val_accuracy: 0.7000\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7324 - val_loss: 0.5783 - val_accuracy: 0.7583\n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7294 - val_loss: 0.5861 - val_accuracy: 0.7333\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7103 - val_loss: 0.6187 - val_accuracy: 0.7167\n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7353 - val_loss: 0.5545 - val_accuracy: 0.7500\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7397 - val_loss: 0.5365 - val_accuracy: 0.7667\n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7294 - val_loss: 0.8675 - val_accuracy: 0.6750\n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7441 - val_loss: 0.6254 - val_accuracy: 0.7250\n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6971 - val_loss: 0.5819 - val_accuracy: 0.7167\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7074 - val_loss: 0.6014 - val_accuracy: 0.7000\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7382 - val_loss: 0.5530 - val_accuracy: 0.7500\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7471 - val_loss: 0.5892 - val_accuracy: 0.6917\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7206 - val_loss: 0.5455 - val_accuracy: 0.7000\n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7515 - val_loss: 0.5897 - val_accuracy: 0.7167\n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7353 - val_loss: 0.5782 - val_accuracy: 0.6917\n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7088 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7412 - val_loss: 0.6224 - val_accuracy: 0.6750\n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7309 - val_loss: 0.5811 - val_accuracy: 0.7250\n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7235 - val_loss: 0.5689 - val_accuracy: 0.7000\n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7471 - val_loss: 0.5755 - val_accuracy: 0.6917\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7221 - val_loss: 0.5606 - val_accuracy: 0.7583\n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7382 - val_loss: 0.5480 - val_accuracy: 0.7667\n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7603 - val_loss: 0.5492 - val_accuracy: 0.7417\n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7544 - val_loss: 0.5714 - val_accuracy: 0.7417\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7676 - val_loss: 0.5220 - val_accuracy: 0.7750\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7750 - val_loss: 0.5655 - val_accuracy: 0.7417\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7868 - val_loss: 0.6806 - val_accuracy: 0.6583\n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7485 - val_loss: 0.6821 - val_accuracy: 0.6750\n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7794 - val_loss: 0.6092 - val_accuracy: 0.7000\n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7559 - val_loss: 0.5533 - val_accuracy: 0.7417\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7868 - val_loss: 0.6272 - val_accuracy: 0.6917\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7397 - val_loss: 0.5631 - val_accuracy: 0.7333\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7515 - val_loss: 0.5952 - val_accuracy: 0.6917\n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7765 - val_loss: 0.5330 - val_accuracy: 0.7500\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7824 - val_loss: 0.5486 - val_accuracy: 0.7750\n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7691 - val_loss: 0.5827 - val_accuracy: 0.7167\n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7794 - val_loss: 0.5373 - val_accuracy: 0.7333\n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7824 - val_loss: 0.5495 - val_accuracy: 0.7417\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7838 - val_loss: 0.5847 - val_accuracy: 0.7250\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7750 - val_loss: 0.5776 - val_accuracy: 0.7167\n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.6714 - val_accuracy: 0.6667\n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7588 - val_loss: 0.5649 - val_accuracy: 0.7333\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7824 - val_loss: 0.5512 - val_accuracy: 0.7250\n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7838 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7912 - val_loss: 0.5766 - val_accuracy: 0.7583\n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7500 - val_loss: 0.5779 - val_accuracy: 0.7417\n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7824 - val_loss: 0.5320 - val_accuracy: 0.7667\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8000 - val_loss: 0.5709 - val_accuracy: 0.7583\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7794 - val_loss: 0.5530 - val_accuracy: 0.7417\n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7779 - val_loss: 0.5392 - val_accuracy: 0.7917\n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7794 - val_loss: 0.5596 - val_accuracy: 0.7417\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7912 - val_loss: 0.5827 - val_accuracy: 0.7000\n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8029 - val_loss: 0.5900 - val_accuracy: 0.7167\n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7868 - val_loss: 0.5515 - val_accuracy: 0.7167\n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.7897 - val_loss: 0.5627 - val_accuracy: 0.7583\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7897 - val_loss: 0.5619 - val_accuracy: 0.7333\n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7971 - val_loss: 0.5601 - val_accuracy: 0.7417\n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7662 - val_loss: 0.5147 - val_accuracy: 0.7583\n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7912 - val_loss: 0.5890 - val_accuracy: 0.7083\n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7897 - val_loss: 0.5586 - val_accuracy: 0.7667\n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7941 - val_loss: 0.5175 - val_accuracy: 0.7833\n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7853 - val_loss: 0.5760 - val_accuracy: 0.7083\n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7956 - val_loss: 0.6223 - val_accuracy: 0.7000\n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8015 - val_loss: 0.5845 - val_accuracy: 0.7583\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.7941 - val_loss: 0.5912 - val_accuracy: 0.7167\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8118 - val_loss: 0.5251 - val_accuracy: 0.7667\n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.7985 - val_loss: 0.5272 - val_accuracy: 0.7917\n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8000 - val_loss: 0.5995 - val_accuracy: 0.7750\n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8059 - val_loss: 0.5720 - val_accuracy: 0.7667\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8118 - val_loss: 0.6391 - val_accuracy: 0.7000\n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8015 - val_loss: 0.5575 - val_accuracy: 0.7333\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8221 - val_loss: 0.5426 - val_accuracy: 0.7583\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.7926 - val_loss: 0.5456 - val_accuracy: 0.7583\n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8000 - val_loss: 0.5654 - val_accuracy: 0.7750\n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8103 - val_loss: 0.5814 - val_accuracy: 0.7667\n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8000 - val_loss: 0.5407 - val_accuracy: 0.7333\n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8044 - val_loss: 0.5851 - val_accuracy: 0.7083\n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7956 - val_loss: 0.5973 - val_accuracy: 0.7167\n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8147 - val_loss: 0.5610 - val_accuracy: 0.7667\n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8044 - val_loss: 0.5428 - val_accuracy: 0.7333\n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8044 - val_loss: 0.6206 - val_accuracy: 0.7083\n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8015 - val_loss: 0.5278 - val_accuracy: 0.7750\n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8250 - val_loss: 0.5661 - val_accuracy: 0.7500\n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8029 - val_loss: 0.5871 - val_accuracy: 0.7250\n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7985 - val_loss: 0.6118 - val_accuracy: 0.7167\n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8191 - val_loss: 0.5510 - val_accuracy: 0.7667\n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8000 - val_loss: 0.5328 - val_accuracy: 0.7667\n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8000 - val_loss: 0.5678 - val_accuracy: 0.7333\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8132 - val_loss: 0.5604 - val_accuracy: 0.7333\n",
            "Epoch 122/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8382 - val_loss: 0.5189 - val_accuracy: 0.7833\n",
            "Epoch 123/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8132 - val_loss: 0.5542 - val_accuracy: 0.7917\n",
            "Epoch 124/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8221 - val_loss: 0.5597 - val_accuracy: 0.7500\n",
            "Epoch 125/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8176 - val_loss: 0.6216 - val_accuracy: 0.7250\n",
            "Epoch 126/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8015 - val_loss: 0.5348 - val_accuracy: 0.7167\n",
            "Epoch 127/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8103 - val_loss: 0.5452 - val_accuracy: 0.7167\n",
            "Epoch 128/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8132 - val_loss: 0.5687 - val_accuracy: 0.7417\n",
            "Epoch 129/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8162 - val_loss: 0.5723 - val_accuracy: 0.7667\n",
            "Epoch 130/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8059 - val_loss: 0.5667 - val_accuracy: 0.7583\n",
            "Epoch 131/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8059 - val_loss: 0.4971 - val_accuracy: 0.7750\n",
            "Epoch 132/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8235 - val_loss: 0.5876 - val_accuracy: 0.7583\n",
            "Epoch 133/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8118 - val_loss: 0.5264 - val_accuracy: 0.7583\n",
            "Epoch 134/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8221 - val_loss: 0.5282 - val_accuracy: 0.7667\n",
            "Epoch 135/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8235 - val_loss: 0.5982 - val_accuracy: 0.7583\n",
            "Epoch 136/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8294 - val_loss: 0.5170 - val_accuracy: 0.7917\n",
            "Epoch 137/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8324 - val_loss: 0.5292 - val_accuracy: 0.7917\n",
            "Epoch 138/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8279 - val_loss: 0.6018 - val_accuracy: 0.7333\n",
            "Epoch 139/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8103 - val_loss: 0.5695 - val_accuracy: 0.7667\n",
            "Epoch 140/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8221 - val_loss: 0.5728 - val_accuracy: 0.8083\n",
            "Epoch 141/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8162 - val_loss: 0.5992 - val_accuracy: 0.7833\n",
            "Epoch 142/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8191 - val_loss: 0.5980 - val_accuracy: 0.7750\n",
            "Epoch 143/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3736 - accuracy: 0.8265 - val_loss: 0.5379 - val_accuracy: 0.7750\n",
            "Epoch 144/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8515 - val_loss: 0.5976 - val_accuracy: 0.7583\n",
            "Epoch 145/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8250 - val_loss: 0.6306 - val_accuracy: 0.7333\n",
            "Epoch 146/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8206 - val_loss: 0.5693 - val_accuracy: 0.7833\n",
            "Epoch 147/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8309 - val_loss: 0.5955 - val_accuracy: 0.7333\n",
            "Epoch 148/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8324 - val_loss: 0.6960 - val_accuracy: 0.7167\n",
            "Epoch 149/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8338 - val_loss: 0.5134 - val_accuracy: 0.8000\n",
            "Epoch 150/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8529 - val_loss: 0.5672 - val_accuracy: 0.7750\n",
            "Epoch 151/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8368 - val_loss: 0.5489 - val_accuracy: 0.8083\n",
            "Epoch 152/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8456 - val_loss: 0.5788 - val_accuracy: 0.7917\n",
            "Epoch 153/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8309 - val_loss: 0.5718 - val_accuracy: 0.7667\n",
            "Epoch 154/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8559 - val_loss: 0.5220 - val_accuracy: 0.7667\n",
            "Epoch 155/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8574 - val_loss: 0.5673 - val_accuracy: 0.7667\n",
            "Epoch 156/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8118 - val_loss: 0.6142 - val_accuracy: 0.7917\n",
            "Epoch 157/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8191 - val_loss: 0.5232 - val_accuracy: 0.7667\n",
            "Epoch 158/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8500 - val_loss: 0.5536 - val_accuracy: 0.7583\n",
            "Epoch 159/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8485 - val_loss: 0.5711 - val_accuracy: 0.7750\n",
            "Epoch 160/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8603 - val_loss: 0.6212 - val_accuracy: 0.7417\n",
            "Epoch 161/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8529 - val_loss: 0.7524 - val_accuracy: 0.6583\n",
            "Epoch 162/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8544 - val_loss: 0.5463 - val_accuracy: 0.8000\n",
            "Epoch 163/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8574 - val_loss: 0.5573 - val_accuracy: 0.7917\n",
            "Epoch 164/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8647 - val_loss: 0.7875 - val_accuracy: 0.7167\n",
            "Epoch 165/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8529 - val_loss: 0.6673 - val_accuracy: 0.7333\n",
            "Epoch 166/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8456 - val_loss: 0.5182 - val_accuracy: 0.7917\n",
            "Epoch 167/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8500 - val_loss: 0.6504 - val_accuracy: 0.7583\n",
            "Epoch 168/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8676 - val_loss: 0.5795 - val_accuracy: 0.7750\n",
            "Epoch 169/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8412 - val_loss: 0.5776 - val_accuracy: 0.7333\n",
            "Epoch 170/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8294 - val_loss: 0.4485 - val_accuracy: 0.8083\n",
            "Epoch 171/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8618 - val_loss: 0.4449 - val_accuracy: 0.8000\n",
            "Epoch 172/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2821 - accuracy: 0.8735 - val_loss: 0.4509 - val_accuracy: 0.8250\n",
            "Epoch 173/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.8529 - val_loss: 0.5605 - val_accuracy: 0.7833\n",
            "Epoch 174/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8691 - val_loss: 0.6002 - val_accuracy: 0.7417\n",
            "Epoch 175/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8397 - val_loss: 0.5730 - val_accuracy: 0.7417\n",
            "Epoch 176/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8515 - val_loss: 0.5690 - val_accuracy: 0.7750\n",
            "Epoch 177/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8456 - val_loss: 0.6371 - val_accuracy: 0.7917\n",
            "Epoch 178/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.8529 - val_loss: 0.6136 - val_accuracy: 0.7667\n",
            "Epoch 179/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.8588 - val_loss: 0.5031 - val_accuracy: 0.8167\n",
            "Epoch 180/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.8647 - val_loss: 0.5474 - val_accuracy: 0.8000\n",
            "Epoch 181/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8721 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 182/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8456 - val_loss: 0.4513 - val_accuracy: 0.8250\n",
            "Epoch 183/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2876 - accuracy: 0.8676 - val_loss: 0.5407 - val_accuracy: 0.7750\n",
            "Epoch 184/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2600 - accuracy: 0.8794 - val_loss: 0.5018 - val_accuracy: 0.8167\n",
            "Epoch 185/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8926 - val_loss: 0.5037 - val_accuracy: 0.8083\n",
            "Epoch 186/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.8824 - val_loss: 0.5080 - val_accuracy: 0.7833\n",
            "Epoch 187/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8735 - val_loss: 0.5744 - val_accuracy: 0.7917\n",
            "Epoch 188/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8544 - val_loss: 0.5424 - val_accuracy: 0.8000\n",
            "Epoch 189/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8735 - val_loss: 0.6096 - val_accuracy: 0.7333\n",
            "Epoch 190/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.8721 - val_loss: 0.4828 - val_accuracy: 0.8000\n",
            "Epoch 191/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8824 - val_loss: 0.4871 - val_accuracy: 0.8083\n",
            "Epoch 192/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8706 - val_loss: 0.7220 - val_accuracy: 0.7583\n",
            "Epoch 193/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2713 - accuracy: 0.8765 - val_loss: 0.5904 - val_accuracy: 0.8000\n",
            "Epoch 194/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.8926 - val_loss: 0.5106 - val_accuracy: 0.7917\n",
            "Epoch 195/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.8882 - val_loss: 0.5611 - val_accuracy: 0.7500\n",
            "Epoch 196/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.8853 - val_loss: 0.4547 - val_accuracy: 0.8083\n",
            "Epoch 197/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2545 - accuracy: 0.8985 - val_loss: 0.4606 - val_accuracy: 0.8000\n",
            "Epoch 198/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.8956 - val_loss: 0.4950 - val_accuracy: 0.8250\n",
            "Epoch 199/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.8926 - val_loss: 0.6260 - val_accuracy: 0.7833\n",
            "Epoch 200/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.8735 - val_loss: 0.6933 - val_accuracy: 0.8000\n",
            "Epoch 201/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.8897 - val_loss: 0.5079 - val_accuracy: 0.8000\n",
            "Epoch 202/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.8956 - val_loss: 0.5104 - val_accuracy: 0.7917\n",
            "Epoch 203/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8868 - val_loss: 0.5010 - val_accuracy: 0.8083\n",
            "Epoch 204/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.8824 - val_loss: 0.5215 - val_accuracy: 0.8250\n",
            "Epoch 205/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.8956 - val_loss: 0.4799 - val_accuracy: 0.7917\n",
            "Epoch 206/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8882 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
            "Epoch 207/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.8868 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
            "Epoch 208/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2533 - accuracy: 0.8853 - val_loss: 0.4503 - val_accuracy: 0.8167\n",
            "Epoch 209/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2160 - accuracy: 0.9074 - val_loss: 0.6046 - val_accuracy: 0.8083\n",
            "Epoch 210/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.8882 - val_loss: 0.4553 - val_accuracy: 0.8667\n",
            "Epoch 211/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.8926 - val_loss: 0.5257 - val_accuracy: 0.8167\n",
            "Epoch 212/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.9147 - val_loss: 0.5432 - val_accuracy: 0.8333\n",
            "Epoch 213/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9118 - val_loss: 0.4994 - val_accuracy: 0.8417\n",
            "Epoch 214/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2382 - accuracy: 0.8897 - val_loss: 0.5308 - val_accuracy: 0.8333\n",
            "Epoch 215/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2553 - accuracy: 0.8779 - val_loss: 0.4740 - val_accuracy: 0.8083\n",
            "Epoch 216/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2311 - accuracy: 0.8941 - val_loss: 0.4871 - val_accuracy: 0.8333\n",
            "Epoch 217/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2445 - accuracy: 0.9029 - val_loss: 0.5232 - val_accuracy: 0.7750\n",
            "Epoch 218/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.8618 - val_loss: 0.4939 - val_accuracy: 0.8083\n",
            "Epoch 219/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8662 - val_loss: 0.5768 - val_accuracy: 0.7833\n",
            "Epoch 220/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.8956 - val_loss: 0.4207 - val_accuracy: 0.8500\n",
            "Epoch 221/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9103 - val_loss: 0.5800 - val_accuracy: 0.7833\n",
            "Epoch 222/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9132 - val_loss: 0.4908 - val_accuracy: 0.8417\n",
            "Epoch 223/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 0.9191 - val_loss: 0.5046 - val_accuracy: 0.8250\n",
            "Epoch 224/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9279 - val_loss: 0.5297 - val_accuracy: 0.8083\n",
            "Epoch 225/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9044 - val_loss: 0.5809 - val_accuracy: 0.8250\n",
            "Epoch 226/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8809 - val_loss: 0.5140 - val_accuracy: 0.8083\n",
            "Epoch 227/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.8985 - val_loss: 0.5717 - val_accuracy: 0.8167\n",
            "Epoch 228/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.8985 - val_loss: 0.4500 - val_accuracy: 0.8083\n",
            "Epoch 229/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.8868 - val_loss: 0.4025 - val_accuracy: 0.8583\n",
            "Epoch 230/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.8750 - val_loss: 0.4939 - val_accuracy: 0.8000\n",
            "Epoch 231/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.8912 - val_loss: 0.5279 - val_accuracy: 0.8417\n",
            "Epoch 232/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.8868 - val_loss: 0.5218 - val_accuracy: 0.8333\n",
            "Epoch 233/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2046 - accuracy: 0.9118 - val_loss: 0.4978 - val_accuracy: 0.8667\n",
            "Epoch 234/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9176 - val_loss: 0.5443 - val_accuracy: 0.7833\n",
            "Epoch 235/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.9176 - val_loss: 0.4827 - val_accuracy: 0.8333\n",
            "Epoch 236/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9162 - val_loss: 0.5284 - val_accuracy: 0.8417\n",
            "Epoch 237/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9309 - val_loss: 0.5670 - val_accuracy: 0.8250\n",
            "Epoch 238/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1840 - accuracy: 0.9250 - val_loss: 0.5453 - val_accuracy: 0.8333\n",
            "Epoch 239/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9382 - val_loss: 0.5324 - val_accuracy: 0.8083\n",
            "Epoch 240/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9088 - val_loss: 0.4853 - val_accuracy: 0.8500\n",
            "Epoch 241/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9250 - val_loss: 0.5050 - val_accuracy: 0.8167\n",
            "Epoch 242/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9368 - val_loss: 0.5145 - val_accuracy: 0.8333\n",
            "Epoch 243/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9147 - val_loss: 0.6781 - val_accuracy: 0.7250\n",
            "Epoch 244/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.8956 - val_loss: 0.4928 - val_accuracy: 0.8083\n",
            "Epoch 245/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9279 - val_loss: 0.5018 - val_accuracy: 0.8583\n",
            "Epoch 246/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9324 - val_loss: 0.5271 - val_accuracy: 0.8167\n",
            "Epoch 247/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9338 - val_loss: 0.6069 - val_accuracy: 0.8000\n",
            "Epoch 248/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9279 - val_loss: 0.5483 - val_accuracy: 0.8250\n",
            "Epoch 249/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9000 - val_loss: 0.5706 - val_accuracy: 0.8250\n",
            "Epoch 250/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9118 - val_loss: 0.5133 - val_accuracy: 0.8000\n",
            "Epoch 251/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9176 - val_loss: 0.6612 - val_accuracy: 0.8417\n",
            "Epoch 252/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9074 - val_loss: 0.5601 - val_accuracy: 0.8333\n",
            "Epoch 253/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9338 - val_loss: 0.5565 - val_accuracy: 0.8333\n",
            "Epoch 254/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9294 - val_loss: 0.5113 - val_accuracy: 0.8500\n",
            "Epoch 255/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9191 - val_loss: 0.5955 - val_accuracy: 0.8167\n",
            "Epoch 256/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9221 - val_loss: 0.5170 - val_accuracy: 0.8333\n",
            "Epoch 257/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9309 - val_loss: 0.5293 - val_accuracy: 0.8167\n",
            "Epoch 258/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9221 - val_loss: 0.4613 - val_accuracy: 0.8083\n",
            "Epoch 259/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9382 - val_loss: 0.5215 - val_accuracy: 0.8500\n",
            "Epoch 260/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9441 - val_loss: 0.5627 - val_accuracy: 0.8167\n",
            "Epoch 261/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9382 - val_loss: 0.6411 - val_accuracy: 0.7917\n",
            "Epoch 262/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9368 - val_loss: 0.5281 - val_accuracy: 0.8417\n",
            "Epoch 263/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9441 - val_loss: 0.5097 - val_accuracy: 0.8417\n",
            "Epoch 264/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9471 - val_loss: 0.5169 - val_accuracy: 0.8167\n",
            "Epoch 265/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9279 - val_loss: 0.4745 - val_accuracy: 0.8333\n",
            "Epoch 266/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9279 - val_loss: 0.5823 - val_accuracy: 0.8333\n",
            "Epoch 267/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9368 - val_loss: 0.4929 - val_accuracy: 0.8000\n",
            "Epoch 268/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9265 - val_loss: 0.5195 - val_accuracy: 0.8167\n",
            "Epoch 269/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9265 - val_loss: 0.5107 - val_accuracy: 0.8500\n",
            "Epoch 270/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9544 - val_loss: 0.5009 - val_accuracy: 0.8417\n",
            "Epoch 271/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9676 - val_loss: 0.4915 - val_accuracy: 0.8667\n",
            "Epoch 272/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9471 - val_loss: 0.5191 - val_accuracy: 0.8667\n",
            "Epoch 273/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9471 - val_loss: 0.5939 - val_accuracy: 0.8250\n",
            "Epoch 274/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9529 - val_loss: 0.6110 - val_accuracy: 0.8417\n",
            "Epoch 275/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9235 - val_loss: 0.5297 - val_accuracy: 0.8250\n",
            "Epoch 276/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1315 - accuracy: 0.9485 - val_loss: 0.6082 - val_accuracy: 0.8500\n",
            "Epoch 277/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9559 - val_loss: 0.5156 - val_accuracy: 0.8333\n",
            "Epoch 278/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9574 - val_loss: 0.5480 - val_accuracy: 0.8583\n",
            "Epoch 279/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9353 - val_loss: 0.4986 - val_accuracy: 0.8333\n",
            "Epoch 280/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9559 - val_loss: 0.4977 - val_accuracy: 0.8583\n",
            "Epoch 281/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.9544 - val_loss: 0.6753 - val_accuracy: 0.8417\n",
            "Epoch 282/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9574 - val_loss: 0.7646 - val_accuracy: 0.7750\n",
            "Epoch 283/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9426 - val_loss: 0.6455 - val_accuracy: 0.8833\n",
            "Epoch 284/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9544 - val_loss: 0.6044 - val_accuracy: 0.8417\n",
            "Epoch 285/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2144 - accuracy: 0.9206 - val_loss: 0.5009 - val_accuracy: 0.8333\n",
            "Epoch 286/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2737 - accuracy: 0.9044 - val_loss: 0.6793 - val_accuracy: 0.8250\n",
            "Epoch 287/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9103 - val_loss: 0.6967 - val_accuracy: 0.8250\n",
            "Epoch 288/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 0.8824 - val_loss: 0.6157 - val_accuracy: 0.7667\n",
            "Epoch 289/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9324 - val_loss: 0.5722 - val_accuracy: 0.8750\n",
            "Epoch 290/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9324 - val_loss: 0.6252 - val_accuracy: 0.8333\n",
            "Epoch 291/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9353 - val_loss: 0.5104 - val_accuracy: 0.8500\n",
            "Epoch 292/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1836 - accuracy: 0.9132 - val_loss: 0.5492 - val_accuracy: 0.8583\n",
            "Epoch 293/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9294 - val_loss: 0.5678 - val_accuracy: 0.8333\n",
            "Epoch 294/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1798 - accuracy: 0.9235 - val_loss: 0.5347 - val_accuracy: 0.8750\n",
            "Epoch 295/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.9324 - val_loss: 0.6523 - val_accuracy: 0.8500\n",
            "Epoch 296/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9559 - val_loss: 0.6057 - val_accuracy: 0.8583\n",
            "Epoch 297/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9544 - val_loss: 0.6124 - val_accuracy: 0.8500\n",
            "Epoch 298/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9691 - val_loss: 0.6047 - val_accuracy: 0.8500\n",
            "Epoch 299/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9618 - val_loss: 0.5971 - val_accuracy: 0.8417\n",
            "Epoch 300/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0984 - accuracy: 0.9603 - val_loss: 0.6379 - val_accuracy: 0.8667\n",
            "Epoch 301/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9632 - val_loss: 0.6664 - val_accuracy: 0.8667\n",
            "Epoch 302/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9706 - val_loss: 0.6341 - val_accuracy: 0.8667\n",
            "Epoch 303/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9544 - val_loss: 0.6302 - val_accuracy: 0.8083\n",
            "Epoch 304/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9632 - val_loss: 0.6372 - val_accuracy: 0.8667\n",
            "Epoch 305/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9721 - val_loss: 0.6349 - val_accuracy: 0.8417\n",
            "Epoch 306/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9721 - val_loss: 0.7015 - val_accuracy: 0.8500\n",
            "Epoch 307/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0769 - accuracy: 0.9809 - val_loss: 0.6163 - val_accuracy: 0.8667\n",
            "Epoch 308/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9721 - val_loss: 0.6861 - val_accuracy: 0.8333\n",
            "Epoch 309/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9721 - val_loss: 0.6365 - val_accuracy: 0.8750\n",
            "Epoch 310/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9662 - val_loss: 0.6691 - val_accuracy: 0.8583\n",
            "Epoch 311/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9735 - val_loss: 0.6856 - val_accuracy: 0.8417\n",
            "Epoch 312/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9735 - val_loss: 0.5943 - val_accuracy: 0.8417\n",
            "Epoch 313/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9559 - val_loss: 0.7677 - val_accuracy: 0.8250\n",
            "Epoch 314/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9338 - val_loss: 0.8920 - val_accuracy: 0.8333\n",
            "Epoch 315/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9471 - val_loss: 0.6694 - val_accuracy: 0.8083\n",
            "Epoch 316/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9426 - val_loss: 0.6019 - val_accuracy: 0.8833\n",
            "Epoch 317/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9559 - val_loss: 0.6192 - val_accuracy: 0.8667\n",
            "Epoch 318/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9721 - val_loss: 0.5969 - val_accuracy: 0.8750\n",
            "Epoch 319/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9809 - val_loss: 0.5884 - val_accuracy: 0.8667\n",
            "Epoch 320/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9794 - val_loss: 0.5883 - val_accuracy: 0.8667\n",
            "Epoch 321/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9397 - val_loss: 0.7109 - val_accuracy: 0.8417\n",
            "Epoch 322/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9529 - val_loss: 0.6603 - val_accuracy: 0.8833\n",
            "Epoch 323/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9794 - val_loss: 0.6119 - val_accuracy: 0.8500\n",
            "Epoch 324/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9838 - val_loss: 0.5730 - val_accuracy: 0.8667\n",
            "Epoch 325/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9824 - val_loss: 0.5906 - val_accuracy: 0.8750\n",
            "Epoch 326/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9765 - val_loss: 0.6348 - val_accuracy: 0.8417\n",
            "Epoch 327/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8868 - val_loss: 0.7642 - val_accuracy: 0.7667\n",
            "Epoch 328/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8912 - val_loss: 0.8892 - val_accuracy: 0.7167\n",
            "Epoch 329/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9324 - val_loss: 0.6347 - val_accuracy: 0.8167\n",
            "Epoch 330/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9632 - val_loss: 0.6612 - val_accuracy: 0.8500\n",
            "Epoch 331/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9618 - val_loss: 0.6476 - val_accuracy: 0.8500\n",
            "Epoch 332/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.9441 - val_loss: 0.5281 - val_accuracy: 0.8333\n",
            "Epoch 333/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9662 - val_loss: 0.7029 - val_accuracy: 0.8083\n",
            "Epoch 334/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9265 - val_loss: 0.6638 - val_accuracy: 0.8000\n",
            "Epoch 335/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.9059 - val_loss: 0.7884 - val_accuracy: 0.8000\n",
            "Epoch 336/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9412 - val_loss: 0.6967 - val_accuracy: 0.8333\n",
            "Epoch 337/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9691 - val_loss: 0.8214 - val_accuracy: 0.8333\n",
            "Epoch 338/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.9662 - val_loss: 0.8208 - val_accuracy: 0.8667\n",
            "Epoch 339/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9721 - val_loss: 0.6538 - val_accuracy: 0.8500\n",
            "Epoch 340/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9838 - val_loss: 0.6345 - val_accuracy: 0.8500\n",
            "Epoch 341/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9853 - val_loss: 0.6539 - val_accuracy: 0.8333\n",
            "Epoch 342/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9838 - val_loss: 0.6960 - val_accuracy: 0.8417\n",
            "Epoch 343/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9853 - val_loss: 0.6987 - val_accuracy: 0.8500\n",
            "Epoch 344/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9765 - val_loss: 0.6654 - val_accuracy: 0.8333\n",
            "Epoch 345/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9882 - val_loss: 0.6366 - val_accuracy: 0.8500\n",
            "Epoch 346/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9882 - val_loss: 0.6982 - val_accuracy: 0.8333\n",
            "Epoch 347/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9779 - val_loss: 0.5968 - val_accuracy: 0.8667\n",
            "Epoch 348/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9779 - val_loss: 0.8568 - val_accuracy: 0.8833\n",
            "Epoch 349/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9868 - val_loss: 0.6425 - val_accuracy: 0.8333\n",
            "Epoch 350/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9882 - val_loss: 0.7500 - val_accuracy: 0.8583\n",
            "Epoch 351/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9897 - val_loss: 0.6588 - val_accuracy: 0.8333\n",
            "Epoch 352/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.7177 - val_accuracy: 0.8750\n",
            "Epoch 353/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9897 - val_loss: 0.6894 - val_accuracy: 0.8500\n",
            "Epoch 354/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9926 - val_loss: 0.7420 - val_accuracy: 0.8417\n",
            "Epoch 355/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.7060 - val_accuracy: 0.8750\n",
            "Epoch 356/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.7025 - val_accuracy: 0.8500\n",
            "Epoch 357/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9882 - val_loss: 0.6705 - val_accuracy: 0.8500\n",
            "Epoch 358/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9647 - val_loss: 0.7359 - val_accuracy: 0.8500\n",
            "Epoch 359/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.7102 - val_accuracy: 0.8417\n",
            "Epoch 360/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9882 - val_loss: 0.7081 - val_accuracy: 0.8583\n",
            "Epoch 361/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9838 - val_loss: 0.7008 - val_accuracy: 0.8583\n",
            "Epoch 362/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9941 - val_loss: 0.7040 - val_accuracy: 0.8500\n",
            "Epoch 363/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9897 - val_loss: 0.7679 - val_accuracy: 0.8250\n",
            "Epoch 364/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.6815 - val_accuracy: 0.8417\n",
            "Epoch 365/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9926 - val_loss: 0.7278 - val_accuracy: 0.8500\n",
            "Epoch 366/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.7270 - val_accuracy: 0.8333\n",
            "Epoch 367/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.8405 - val_accuracy: 0.8583\n",
            "Epoch 368/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9647 - val_loss: 0.9444 - val_accuracy: 0.8333\n",
            "Epoch 369/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8926 - val_loss: 0.7011 - val_accuracy: 0.8500\n",
            "Epoch 370/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2149 - accuracy: 0.9206 - val_loss: 0.7237 - val_accuracy: 0.8583\n",
            "Epoch 371/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9471 - val_loss: 0.5873 - val_accuracy: 0.8667\n",
            "Epoch 372/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9559 - val_loss: 0.6398 - val_accuracy: 0.8083\n",
            "Epoch 373/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.9676 - val_loss: 0.7278 - val_accuracy: 0.8333\n",
            "Epoch 374/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9750 - val_loss: 0.6561 - val_accuracy: 0.8417\n",
            "Epoch 375/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9809 - val_loss: 0.5597 - val_accuracy: 0.8667\n",
            "Epoch 376/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9765 - val_loss: 0.5975 - val_accuracy: 0.8417\n",
            "Epoch 377/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9838 - val_loss: 0.6068 - val_accuracy: 0.8417\n",
            "Epoch 378/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.5921 - val_accuracy: 0.8583\n",
            "Epoch 379/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9853 - val_loss: 0.6342 - val_accuracy: 0.8583\n",
            "Epoch 380/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9971 - val_loss: 0.6133 - val_accuracy: 0.8333\n",
            "Epoch 381/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9956 - val_loss: 0.6170 - val_accuracy: 0.8583\n",
            "Epoch 382/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.6885 - val_accuracy: 0.8667\n",
            "Epoch 383/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9926 - val_loss: 0.6106 - val_accuracy: 0.8250\n",
            "Epoch 384/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9941 - val_loss: 0.7309 - val_accuracy: 0.8250\n",
            "Epoch 385/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.5950 - val_accuracy: 0.8583\n",
            "Epoch 386/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9971 - val_loss: 0.6586 - val_accuracy: 0.8583\n",
            "Epoch 387/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9956 - val_loss: 0.6170 - val_accuracy: 0.8417\n",
            "Epoch 388/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9941 - val_loss: 0.6526 - val_accuracy: 0.8500\n",
            "Epoch 389/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9956 - val_loss: 0.6673 - val_accuracy: 0.8583\n",
            "Epoch 390/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.6361 - val_accuracy: 0.8500\n",
            "Epoch 391/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9985 - val_loss: 0.6775 - val_accuracy: 0.8583\n",
            "Epoch 392/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 0.6342 - val_accuracy: 0.8417\n",
            "Epoch 393/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9985 - val_loss: 0.6260 - val_accuracy: 0.8833\n",
            "Epoch 394/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9794 - val_loss: 0.7013 - val_accuracy: 0.8417\n",
            "Epoch 395/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9897 - val_loss: 0.6752 - val_accuracy: 0.8667\n",
            "Epoch 396/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9809 - val_loss: 0.7161 - val_accuracy: 0.8583\n",
            "Epoch 397/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9868 - val_loss: 0.6098 - val_accuracy: 0.8333\n",
            "Epoch 398/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9662 - val_loss: 0.6624 - val_accuracy: 0.8250\n",
            "Epoch 399/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9926 - val_loss: 0.6816 - val_accuracy: 0.8500\n",
            "Epoch 400/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9956 - val_loss: 0.6566 - val_accuracy: 0.8250\n",
            "Epoch 401/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: 0.6635 - val_accuracy: 0.8750\n",
            "Epoch 402/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9971 - val_loss: 0.7158 - val_accuracy: 0.8833\n",
            "Epoch 403/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9779 - val_loss: 0.6196 - val_accuracy: 0.8667\n",
            "Epoch 404/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.9000 - val_loss: 0.7923 - val_accuracy: 0.8167\n",
            "Epoch 405/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.9279 - val_loss: 0.8216 - val_accuracy: 0.8167\n",
            "Epoch 406/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.9132 - val_loss: 0.5496 - val_accuracy: 0.8500\n",
            "Epoch 407/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.1659 - accuracy: 0.9471 - val_loss: 0.9348 - val_accuracy: 0.8250\n",
            "Epoch 408/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9529 - val_loss: 0.7160 - val_accuracy: 0.8167\n",
            "Epoch 409/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9676 - val_loss: 0.6399 - val_accuracy: 0.8667\n",
            "Epoch 410/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9779 - val_loss: 0.6819 - val_accuracy: 0.8500\n",
            "Epoch 411/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9882 - val_loss: 0.6162 - val_accuracy: 0.8750\n",
            "Epoch 412/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8583\n",
            "Epoch 413/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9971 - val_loss: 0.6646 - val_accuracy: 0.8833\n",
            "Epoch 414/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9985 - val_loss: 0.6760 - val_accuracy: 0.8417\n",
            "Epoch 415/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.6837 - val_accuracy: 0.8750\n",
            "Epoch 416/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9971 - val_loss: 0.6661 - val_accuracy: 0.9000\n",
            "Epoch 417/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.7246 - val_accuracy: 0.8250\n",
            "Epoch 418/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.6925 - val_accuracy: 0.8500\n",
            "Epoch 419/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 0.7081 - val_accuracy: 0.8667\n",
            "Epoch 420/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9985 - val_loss: 0.7067 - val_accuracy: 0.8750\n",
            "Epoch 421/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.6911 - val_accuracy: 0.8500\n",
            "Epoch 422/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9971 - val_loss: 0.7138 - val_accuracy: 0.8667\n",
            "Epoch 423/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.6879 - val_accuracy: 0.8500\n",
            "Epoch 424/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.8167\n",
            "Epoch 425/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9985 - val_loss: 0.7114 - val_accuracy: 0.8583\n",
            "Epoch 426/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.7420 - val_accuracy: 0.8667\n",
            "Epoch 427/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.7840 - val_accuracy: 0.8750\n",
            "Epoch 428/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.7262 - val_accuracy: 0.8583\n",
            "Epoch 429/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.7414 - val_accuracy: 0.8750\n",
            "Epoch 430/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.7427 - val_accuracy: 0.8667\n",
            "Epoch 431/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8417\n",
            "Epoch 432/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.8417\n",
            "Epoch 433/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9971 - val_loss: 0.7508 - val_accuracy: 0.8333\n",
            "Epoch 434/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.7371 - val_accuracy: 0.8667\n",
            "Epoch 435/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9926 - val_loss: 0.9033 - val_accuracy: 0.8333\n",
            "Epoch 436/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2224 - accuracy: 0.9426 - val_loss: 0.8721 - val_accuracy: 0.8583\n",
            "Epoch 437/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9426 - val_loss: 0.9577 - val_accuracy: 0.7917\n",
            "Epoch 438/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.9074 - val_loss: 0.9755 - val_accuracy: 0.8417\n",
            "Epoch 439/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9426 - val_loss: 0.6953 - val_accuracy: 0.8417\n",
            "Epoch 440/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.9235 - val_loss: 0.8428 - val_accuracy: 0.8250\n",
            "Epoch 441/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9441 - val_loss: 0.9183 - val_accuracy: 0.7833\n",
            "Epoch 442/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9397 - val_loss: 0.6949 - val_accuracy: 0.7667\n",
            "Epoch 443/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9676 - val_loss: 0.8174 - val_accuracy: 0.8583\n",
            "Epoch 444/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9838 - val_loss: 0.8110 - val_accuracy: 0.8417\n",
            "Epoch 445/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.7302 - val_accuracy: 0.8833\n",
            "Epoch 446/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8667\n",
            "Epoch 447/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8667\n",
            "Epoch 448/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 0.8417\n",
            "Epoch 449/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.7421 - val_accuracy: 0.8667\n",
            "Epoch 450/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.7387 - val_accuracy: 0.8833\n",
            "Epoch 451/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9985 - val_loss: 0.7687 - val_accuracy: 0.8583\n",
            "Epoch 452/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 0.8667\n",
            "Epoch 453/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.8500\n",
            "Epoch 454/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8583\n",
            "Epoch 455/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8417\n",
            "Epoch 456/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.8417\n",
            "Epoch 457/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7856 - val_accuracy: 0.8583\n",
            "Epoch 458/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.8500\n",
            "Epoch 459/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.8170 - val_accuracy: 0.8583\n",
            "Epoch 460/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.8333\n",
            "Epoch 461/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.8583\n",
            "Epoch 462/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.8583\n",
            "Epoch 463/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.8583\n",
            "Epoch 464/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.8667\n",
            "Epoch 465/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.8333\n",
            "Epoch 466/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.8750\n",
            "Epoch 467/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.8333\n",
            "Epoch 468/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8055 - val_accuracy: 0.8250\n",
            "Epoch 469/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.8750\n",
            "Epoch 470/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.8500\n",
            "Epoch 471/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.8575 - val_accuracy: 0.8333\n",
            "Epoch 472/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.8333\n",
            "Epoch 473/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.8054 - val_accuracy: 0.8750\n",
            "Epoch 474/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.8222 - val_accuracy: 0.8500\n",
            "Epoch 475/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.8091 - val_accuracy: 0.8750\n",
            "Epoch 476/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.8313 - val_accuracy: 0.8583\n",
            "Epoch 477/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.8833\n",
            "Epoch 478/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9985 - val_loss: 0.7939 - val_accuracy: 0.8333\n",
            "Epoch 479/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2553 - accuracy: 0.9426 - val_loss: 0.9821 - val_accuracy: 0.7833\n",
            "Epoch 480/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.8853 - val_loss: 1.2704 - val_accuracy: 0.7667\n",
            "Epoch 481/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.9103 - val_loss: 0.9347 - val_accuracy: 0.7583\n",
            "Epoch 482/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.9632 - val_loss: 0.8227 - val_accuracy: 0.8583\n",
            "Epoch 483/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9706 - val_loss: 0.9104 - val_accuracy: 0.8167\n",
            "Epoch 484/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9691 - val_loss: 0.8183 - val_accuracy: 0.8333\n",
            "Epoch 485/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9912 - val_loss: 0.8816 - val_accuracy: 0.8167\n",
            "Epoch 486/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.8406 - val_accuracy: 0.8667\n",
            "Epoch 487/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.8172 - val_accuracy: 0.8667\n",
            "Epoch 488/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.8352 - val_accuracy: 0.8167\n",
            "Epoch 489/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.7980 - val_accuracy: 0.8250\n",
            "Epoch 490/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9971 - val_loss: 0.7900 - val_accuracy: 0.8417\n",
            "Epoch 491/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.8417\n",
            "Epoch 492/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8352 - val_accuracy: 0.8417\n",
            "Epoch 493/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.8193 - val_accuracy: 0.8500\n",
            "Epoch 494/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8288 - val_accuracy: 0.8667\n",
            "Epoch 495/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8646 - val_accuracy: 0.8667\n",
            "Epoch 496/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.8354 - val_accuracy: 0.8667\n",
            "Epoch 497/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8340 - val_accuracy: 0.8667\n",
            "Epoch 498/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.8333\n",
            "Epoch 499/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.8333\n",
            "Epoch 500/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.8750\n"
          ]
        }
      ]
    }
  ]
}